{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSaBTo8v5P+QcavuHFU8w3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaiju8/GANs-Implemented/blob/main/DCGANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fqBX1lyUL5x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            nn.Conv2d(channels, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.disc(x)"
      ],
      "metadata": {
        "id": "4f8aXkdBFPA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_dim, channels):\n",
        "        super(Generator, self).__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            \n",
        "            nn.ConvTranspose2d(noise_dim, 1024, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(1024, 512, kernel_size=4,stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.gen(x)"
      ],
      "metadata": {
        "id": "HwqksnvIIDZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m , (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
      ],
      "metadata": {
        "id": "vdlnCBmtNdsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "RDw-cGEsOx89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 2e-4  \n",
        "z_dim = 100 \n",
        "img_dim = 64\n",
        "channels_img = 1\n",
        "batch_size = 128\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "mwQ1Q6RUQn1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc = Discriminator(channels_img).to(device)\n",
        "gen = Generator(z_dim, channels_img).to(device)"
      ],
      "metadata": {
        "id": "UTUq0ckZ0ola"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary(disc, input_size = (channels_img, img_dim, img_dim), batch_size = -42))\n",
        "print(summary(gen, input_size = (z_dim, 1, 1), batch_size = -42))"
      ],
      "metadata": {
        "id": "Hx2NuRtt32R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(img_dim),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5 for _ in range(channels_img)],[0.5 for _ in range(channels_img)]),     \n",
        "    ]\n",
        ") "
      ],
      "metadata": {
        "id": "gZDfgbYPzJ34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.MNIST(root = \"dataset\", transform = transforms, download = True)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "RXh8nE9O0nBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initialize_weights(disc)\n",
        "initialize_weights(gen)\n",
        "\n",
        "opt_disc = optim.Adam(disc.parameters(), lr = lr, betas=(0.5,0.999))\n",
        "opt_gen = optim.Adam(gen.parameters(), lr = lr, betas=(0.5,0.999))"
      ],
      "metadata": {
        "id": "29YkY2sY0txk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "YmRLcncc1QXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_noise = torch.randn((32, z_dim, 1, 1)).to(device)"
      ],
      "metadata": {
        "id": "uJe7N1i51RHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_img(generator, fixed_noise, channels, img_dim):\n",
        "    \n",
        "    fake = generator(fixed_noise).reshape(-1, channels, img_dim, img_dim)\n",
        "    img_grid = torchvision.utils.make_grid(fake, normalize=True)\n",
        "    return img_grid"
      ],
      "metadata": {
        "id": "03-gzddYq_KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_interpolation(generator, z_dim, channels, img_dim):\n",
        "\n",
        "    point_1 = torch.randn((1, z_dim, 1, 1)).to(device)\n",
        "    point_2 = torch.randn((1, z_dim, 1, 1)).to(device)\n",
        "\n",
        "    interpolated = point_1.detach().clone()\n",
        "    for i in range(1, 16, 1):\n",
        "        inter = torch.lerp(point_1, point_2,(i/15.0)).to(device)\n",
        "        interpolated = torch.cat((interpolated, inter), 0).to(device)\n",
        "        \n",
        "    imgs = gen(interpolated).reshape(-1, channels_img, img_dim, img_dim)\n",
        "    img_grid = torchvision.utils.make_grid(imgs, normalize=True)\n",
        "    return img_grid"
      ],
      "metadata": {
        "id": "9XgJqoj5srQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_grid(imgs): #Show function from documentation\n",
        "    if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
        "    for i, img in enumerate(imgs):\n",
        "        img = img.detach()\n",
        "        img = F.to_pil_image(img)\n",
        "        axs[0, i].imshow(np.asarray(img))\n",
        "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
      ],
      "metadata": {
        "id": "ocD5DriC28QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_disc(real_img, fake_img, optim):\n",
        "\n",
        "    optim.zero_grad()\n",
        "\n",
        "    #Discriminator max log(D(real)) + log(1 - D(G(z)))\n",
        "\n",
        "    disc_real = disc(real_img).reshape(-1)\n",
        "    loss_real = criterion(disc_real, torch.ones_like(disc_real))\n",
        "\n",
        "    disc_fake = disc(fake_img).reshape(-1)# detach for generator stuff or a\n",
        "    loss_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "\n",
        "    loss_D = (loss_real + loss_fake)/2\n",
        "\n",
        "    loss_D.backward()\n",
        "    \n",
        "    opt_disc.step()\n",
        "\n",
        "    return loss_D\n",
        "\n",
        "def train_gen(fake_img, optim):\n",
        "\n",
        "    optim.zero_grad()\n",
        "    \n",
        "    #Discriminator min log(1 - D(G(z))) but better to max log(D(G(z)))\n",
        "    output = disc(fake_img).reshape(-1)\n",
        "    loss_G = criterion(output, torch.ones_like(output))\n",
        "\n",
        "    loss_G.backward()\n",
        "\n",
        "    opt_gen.step()\n",
        "\n",
        "    return loss_G\n"
      ],
      "metadata": {
        "id": "J9ZNAR-SjRiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses_g = []\n",
        "losses_d = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    loss_d = 0.0\n",
        "    loss_g = 0.0\n",
        "\n",
        "    for batch_idx, (real, _) in enumerate(loader):\n",
        "\n",
        "        real = real.to(device)\n",
        "        batch_size = real.shape[0]\n",
        "\n",
        "\n",
        "        noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)\n",
        "        fake = gen(noise).detach()\n",
        "\n",
        "        loss_d = train_disc(real, fake, opt_disc)\n",
        "        losses_d.append(loss_d.detach().cpu())\n",
        "\n",
        "\n",
        "        noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)\n",
        "        fake = gen(noise)\n",
        "\n",
        "        loss_g = train_gen(fake, opt_gen)\n",
        "        losses_g.append(loss_g.detach().cpu())\n",
        "\n",
        "###################################################\n",
        "        #if batch_idx%100 == 0:\n",
        "        print(f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} Discriminator loss: {loss_d:.4f}, Generator loss: {loss_g:.4f}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            show_grid(generate_img(gen, fixed_noise, channels_img, img_dim))\n",
        "####################################################\n",
        "\n",
        "show_grid(generate_img(gen, fixed_noise, channels_img, img_dim))"
      ],
      "metadata": {
        "id": "wBPLZb6l1i4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_img = generate_img(gen, fixed_noise, channels_img, img_dim)\n",
        "show_grid(sample_img)\n",
        "save_image(sample_img, \"result.png\")"
      ],
      "metadata": {
        "id": "IGsDInYHuTXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpolation_img = generate_interpolation(gen, z_dim, channels_img, img_dim)\n",
        "show_grid(interpolation_img)\n",
        "save_image(interpolation_img, \"interpolation.png\")"
      ],
      "metadata": {
        "id": "nGkU6hDTCiAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(losses_g, label='Generator loss')\n",
        "plt.plot(losses_d, label='Discriminator Loss')\n",
        "plt.legend()\n",
        "plt.savefig(\"loss.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RMdUpqEE2iNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uXTswUwK6I6X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}